(window.webpackJsonp=window.webpackJsonp||[]).push([[153],{549:function(t,a,r){"use strict";r.r(a);var s=r(2),e=Object(s.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"ch19-resnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ch19-resnet"}},[t._v("#")]),t._v(" Ch19 ResNet")]),t._v(" "),a("p",[t._v("使用残差跳连，引入了前方信息，缓解梯度消失，使神经网络层数增加成为可能")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220702175714219.png",alt:"image-20220702175714219"}})]),t._v(" "),a("ul",[a("li",[t._v("何凯明表示，单纯堆叠神经网络，会使神经网络退化，后面的神经网络会丢失最初始神经网络的特征，所以他用了跳连线，将前期的特征直接接到了后面"),a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220702175841954.png",alt:"image-20220702175841954"}})]),t._v(" "),a("li",[a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220702175939812.png",alt:"image-20220702175939812"}})])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220702180100970.png",alt:"image-20220702180100970"}})]),t._v(" "),a("ul",[a("li",[t._v("如果维度不同，调用红色框里的代码")]),t._v(" "),a("li",[t._v("如果维度相同，则直接相加")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220703124149716.png",alt:"image-20220703124149716"}})]),t._v(" "),a("ul",[a("li",[t._v("residual_path=true 用虚线连接， residual_path=false 用实线连接")]),t._v(" "),a("li",[t._v("block_list表示每个橙色块（block）中有几个ResnetBlock")])]),t._v(" "),a("p",[t._v("filter=卷积核的个数就是输出的深度"),a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220703124947423.png",alt:"image-20220703124947423"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://markdown-1301334775.cos.eu-frankfurt.myqcloud.com/image-20220703131331007.png",alt:"image-20220703131331007"}})])])}),[],!1,null,null,null);a.default=e.exports}}]);